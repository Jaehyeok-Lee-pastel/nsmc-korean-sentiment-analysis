"""
NSMC ë°ì´í„° ë¡œë”© ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ NSMC(Naver Sentiment Movie Corpus) ë°ì´í„°ì…‹ì„ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë¡œë”©í•˜ëŠ” 
í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ìë™ ê²½ë¡œ íƒì§€
- ë‹¤ì¤‘ ì¸ì½”ë”© ì§€ì› 
- ë°ì´í„° ê²€ì¦
- ê°œë°œìš© ìƒ˜í”Œë§
- ìƒì„¸í•œ ë¡œê¹…

ì‘ì„±ì: ì´ì¬í˜
ì‘ì„±ì¼: 2025-01-17
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Tuple, Optional, List
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def find_data_directory(possible_paths: Optional[List[str]] = None) -> Optional[Path]:
    """
    NSMC ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ íƒì§€í•©ë‹ˆë‹¤.
    
    Args:
        possible_paths: íƒìƒ‰í•  ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: None)
        
    Returns:
        Path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ, ì°¾ì§€ ëª»í•˜ë©´ None
    """
    
    if possible_paths is None:
        possible_paths = [
            'data/raw',           # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
            '../data/raw',        # notebooks í´ë”ì—ì„œ ì‹¤í–‰  
            '../../data/raw',     # notebooks/01_data_explorationì—ì„œ ì‹¤í–‰
            './data/raw',         # ëª…ì‹œì  í˜„ì¬ ë””ë ‰í† ë¦¬
            '../../../data/raw'   # ë” ê¹Šì€ ìœ„ì¹˜ì—ì„œ ì‹¤í–‰
        ]
    
    # ì§ì ‘ ê²½ë¡œ í™•ì¸
    for path in possible_paths:
        if os.path.exists(path):
            data_dir = Path(path)
            logger.info(f"âœ… ë°ì´í„° í´ë” ë°œê²¬: {data_dir.absolute()}")
            return data_dir
    
    # íŒŒì¼ ì‹œìŠ¤í…œ ê²€ìƒ‰
    logger.info("ğŸ” ë°ì´í„° í´ë”ë¥¼ ì§ì ‘ ê²€ìƒ‰ ì¤‘...")
    for root, dirs, files in os.walk('.'):
        if 'ratings_train.txt' in files:
            data_dir = Path(root)
            logger.info(f"âœ… ë°ì´í„° í´ë” ë°œê²¬: {data_dir.absolute()}")
            return data_dir
    
    return None


def load_data_with_encoding(file_path: Path, 
                          encodings: List[str] = None) -> pd.DataFrame:
    """
    ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.
    
    Args:
        file_path: ë¡œë”©í•  íŒŒì¼ ê²½ë¡œ
        encodings: ì‹œë„í•  ì¸ì½”ë”© ë¦¬ìŠ¤íŠ¸
        
    Returns:
        DataFrame: ë¡œë”©ëœ ë°ì´í„°í”„ë ˆì„
        
    Raises:
        Exception: ëª¨ë“  ì¸ì½”ë”©ì´ ì‹¤íŒ¨í•œ ê²½ìš°
    """
    
    if encodings is None:
        encodings = ['utf-8', 'cp949', 'euc-kr']
    
    for encoding in encodings:
        try:
            logger.info(f"ğŸ“Š {file_path.name} ë¡œë”© ì‹œë„ (ì¸ì½”ë”©: {encoding})...")
            df = pd.read_csv(file_path, sep='\t', encoding=encoding)
            logger.info(f"âœ… {file_path.name} ë¡œë”© ì„±ê³µ! (ì¸ì½”ë”©: {encoding})")
            return df
            
        except UnicodeDecodeError:
            logger.warning(f"âŒ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨, ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„...")
            continue
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ ({encoding}): {e}")
            continue
    
    raise Exception(f"ëª¨ë“  ì¸ì½”ë”©ìœ¼ë¡œ {file_path.name} ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


def validate_nsmc_data(df: pd.DataFrame, data_type: str) -> bool:
    """
    NSMC ë°ì´í„°ì˜ í˜•ì‹ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        df: ê²€ì¦í•  ë°ì´í„°í”„ë ˆì„
        data_type: ë°ì´í„° íƒ€ì… ('train' ë˜ëŠ” 'test')
        
    Returns:
        bool: ê²€ì¦ í†µê³¼ ì—¬ë¶€
    """
    
    logger.info(f"ğŸ” {data_type} ë°ì´í„° ê²€ì¦ ì¤‘...")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['id', 'document', 'label']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        logger.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        return False
    
    # ë°ì´í„° í¬ê¸° í™•ì¸
    expected_sizes = {'train': 150000, 'test': 50000}
    if data_type in expected_sizes:
        expected_size = expected_sizes[data_type]
        actual_size = len(df)
        
        if abs(actual_size - expected_size) > expected_size * 0.01:  # 1% ì˜¤ì°¨ í—ˆìš©
            logger.warning(f"âš ï¸ {data_type} ë°ì´í„° í¬ê¸° ë¶ˆì¼ì¹˜: ì˜ˆìƒ {expected_size:,}, ì‹¤ì œ {actual_size:,}")
    
    # ë¼ë²¨ ê°’ í™•ì¸
    unique_labels = df['label'].unique()
    expected_labels = {0, 1}
    if not set(unique_labels).issubset(expected_labels):
        logger.error(f"âŒ ì˜ëª»ëœ ë¼ë²¨ ê°’: {unique_labels}")
        return False
    
    # ê²°ì¸¡ê°’ í™•ì¸
    null_counts = df.isnull().sum()
    if null_counts.any():
        logger.warning(f"âš ï¸ ê²°ì¸¡ê°’ ë°œê²¬:\n{null_counts[null_counts > 0]}")
    
    logger.info(f"âœ… {data_type} ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
    return True


def get_data_summary(train_df: pd.DataFrame, test_df: pd.DataFrame) -> None:
    """
    ë°ì´í„°ì˜ ê¸°ë³¸ ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        train_df: í›ˆë ¨ ë°ì´í„°í”„ë ˆì„
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„
    """
    
    print("=" * 50)
    print("ğŸ“Š NSMC ë°ì´í„°ì…‹ ìš”ì•½")
    print("=" * 50)
    
    # ê¸°ë³¸ ì •ë³´
    total_reviews = len(train_df) + len(test_df)
    print(f"   ì „ì²´ ë¦¬ë·° ìˆ˜: {total_reviews:,}ê°œ")
    print(f"   í›ˆë ¨ ë°ì´í„°: {len(train_df):,}ê°œ ({len(train_df)/total_reviews*100:.1f}%)")
    print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df):,}ê°œ ({len(test_df)/total_reviews*100:.1f}%)")
    
    # ê°ì • ë¶„í¬
    print(f"\nğŸ“ˆ ê°ì • ë¶„í¬:")
    train_pos = (train_df['label'] == 1).sum()
    train_neg = (train_df['label'] == 0).sum()
    test_pos = (test_df['label'] == 1).sum()
    test_neg = (test_df['label'] == 0).sum()
    
    print(f"   í›ˆë ¨ - ê¸ì •: {train_pos:,}ê°œ ({train_pos/len(train_df)*100:.1f}%), "
          f"ë¶€ì •: {train_neg:,}ê°œ ({train_neg/len(train_df)*100:.1f}%)")
    print(f"   í…ŒìŠ¤íŠ¸ - ê¸ì •: {test_pos:,}ê°œ ({test_pos/len(test_df)*100:.1f}%), "
          f"ë¶€ì •: {test_neg:,}ê°œ ({test_neg/len(test_df)*100:.1f}%)")
    
    # ìƒ˜í”Œ ë°ì´í„°
    print(f"\nğŸ‘€ í›ˆë ¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
    print(train_df.head(3).to_string())
    print("=" * 50)


def load_nsmc_data(data_path: Optional[str] = None,
                   sample_size: Optional[int] = None,
                   random_state: int = 42,
                   verbose: bool = True,
                   validate: bool = True) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    NSMC ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.
    
    Args:
        data_path: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ìë™ íƒì§€)
        sample_size: ë¡œë”©í•  ìƒ˜í”Œ í¬ê¸° (ê¸°ë³¸ê°’: ì „ì²´ ë°ì´í„°)
        random_state: ìƒ˜í”Œë§ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        validate: ë°ì´í„° ê²€ì¦ ìˆ˜í–‰ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
    Returns:
        Tuple[DataFrame, DataFrame]: (í›ˆë ¨ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„°)
        
    Raises:
        FileNotFoundError: ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        Exception: ë°ì´í„° ë¡œë”©ì´ ì‹¤íŒ¨í•œ ê²½ìš°
    """
    
    # ë¡œê¹… ë ˆë²¨ ì¡°ì •
    if not verbose:
        logger.setLevel(logging.WARNING)
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ì°¾ê¸°
    if data_path:
        data_dir = Path(data_path)
        if not data_dir.exists():
            raise FileNotFoundError(f"ì§€ì •í•œ ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
    else:
        data_dir = find_data_directory()
        if data_dir is None:
            raise FileNotFoundError(
                "NSMC ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "data/raw/ í´ë”ì— ratings_train.txtì™€ ratings_test.txtê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    train_file = data_dir / 'ratings_train.txt'
    test_file = data_dir / 'ratings_test.txt'
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not train_file.exists():
        raise FileNotFoundError(f"í›ˆë ¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_file}")
    if not test_file.exists():
        raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file}")
    
    if verbose:
        print("ğŸ“ ë°ì´í„° íŒŒì¼ í™•ì¸:")
        print(f"   í›ˆë ¨ ë°ì´í„°: {train_file} ({train_file.stat().st_size:,} bytes)")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_file} ({test_file.stat().st_size:,} bytes)")
    
    # ë°ì´í„° ë¡œë”©
    train_df = load_data_with_encoding(train_file)
    test_df = load_data_with_encoding(test_file)
    
    # ë°ì´í„° ê²€ì¦
    if validate:
        train_valid = validate_nsmc_data(train_df, 'train')
        test_valid = validate_nsmc_data(test_df, 'test')
        
        if not (train_valid and test_valid):
            logger.warning("âš ï¸ ë°ì´í„° ê²€ì¦ ì¤‘ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìƒ˜í”Œë§ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
    if sample_size:
        if sample_size > len(train_df):
            logger.warning(f"âš ï¸ ìš”ì²­ëœ ìƒ˜í”Œ í¬ê¸°({sample_size})ê°€ ì „ì²´ ë°ì´í„°ë³´ë‹¤ í½ë‹ˆë‹¤.")
        else:
            train_df = train_df.sample(n=min(sample_size, len(train_df)), 
                                     random_state=random_state).reset_index(drop=True)
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ë¹„ë¡€ì ìœ¼ë¡œ ìƒ˜í”Œë§
            test_sample_size = int(sample_size * len(test_df) / (len(train_df) + len(test_df)))
            test_df = test_df.sample(n=min(test_sample_size, len(test_df)), 
                                   random_state=random_state).reset_index(drop=True)
            
            if verbose:
                print(f"ğŸ“Š ìƒ˜í”Œë§ ì™„ë£Œ: í›ˆë ¨ {len(train_df):,}ê°œ, í…ŒìŠ¤íŠ¸ {len(test_df):,}ê°œ")
    
    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    if verbose:
        get_data_summary(train_df, test_df)
    
    return train_df, test_df


# í¸ì˜ í•¨ìˆ˜ë“¤
def load_nsmc_sample(sample_size: int = 1000, random_state: int = 42):
    """ê°œë°œìš© ìƒ˜í”Œ ë°ì´í„° ë¡œë”©"""
    return load_nsmc_data(sample_size=sample_size, random_state=random_state)


def load_nsmc_quiet():
    """ì¡°ìš©í•œ ëª¨ë“œë¡œ ë°ì´í„° ë¡œë”©"""
    return load_nsmc_data(verbose=False)


if __name__ == "__main__":
    # ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª data_loader.py ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    try:
        train_df, test_df = load_nsmc_data()
        print("âœ… ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")