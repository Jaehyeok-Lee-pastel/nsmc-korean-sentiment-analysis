"""
í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ëª¨ë“ˆ

NSMC í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
ì—¬ëŸ¬ ë…¸íŠ¸ë¶ì—ì„œ ì¼ê´€ëœ ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ ëª¨ë“ˆí™”í–ˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ì œ
- ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- ê°„ë‹¨í•œ í† í°í™”

ì‘ì„±ì: ì´ì¬í˜
ì‘ì„±ì¼: 2025-01-17
"""

import pandas as pd
import numpy as np
import re
from tqdm import tqdm
from typing import List, Union
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


def clean_korean_text(text: Union[str, float]) -> str:
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜
    
    ì´ëª¨í‹°ì½˜ê³¼ ê°ì • í‘œí˜„ì€ ë³´ì¡´í•˜ë©´ì„œ ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: ì •ì œëœ í…ìŠ¤íŠ¸
        
    Examples:
        >>> clean_korean_text("ã…‹ã…‹ã…‹ã…‹ ë„ˆë¬´ ì¬ë°Œì–´ìš”!!!!")
        'ã…‹ã…‹ ë„ˆë¬´ ì¬ë°Œì–´ìš”!!'
        
        >>> clean_korean_text("ì´ ì˜í™”...ì •ë§ ìµœê³ ì…ë‹ˆë‹¤")
        'ì´ ì˜í™”...ì •ë§ ìµœê³ ì…ë‹ˆë‹¤'
    """
    if pd.isna(text) or text == '':
        return ''
    
    # 1. ë¬¸ìì—´ë¡œ ë³€í™˜
    text = str(text)
    
    # 2. ë°˜ë³µ ë¬¸ì ì •ê·œí™” (3ê°œ ì´ìƒ â†’ 2ê°œ)
    # ì´ëª¨í‹°ì½˜ ì •ê·œí™”
    text = re.sub(r'([ã…‹ã…ã… ã…œã…¡ã…—ã…›ã…•ã…‘ã…ã…“ã…£])\1{2,}', r'\1\1', text)
    # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
    text = re.sub(r'([!?.])\\1{2,}', r'\1\1', text)
    
    # 3. íŠ¹ìˆ˜ë¬¸ì ì¤‘ ì˜ë¯¸ì—†ëŠ” ê²ƒë“¤ ì œê±° (ê°ì • í‘œí˜„ì€ ë³´ì¡´)
    # ë³´ì¡´í•  íŒ¨í„´: ã…‹ã…‹, ã…ã…, ã… ã… , ã…œã…œ, !!!, ???, ...
    text = re.sub(r'[^\w\sã…‹ã…ã… ã…œã…¡ã…—ã…›ã…•ã…‘ã…ã…“ã…£!?.,~\-]', ' ', text)
    
    # 4. ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    
    # 5. ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text


def simple_korean_tokenize(text: Union[str, float]) -> List[str]:
    """
    ê°„ë‹¨í•œ í•œêµ­ì–´ í† í°í™” í•¨ìˆ˜
    (í˜•íƒœì†Œ ë¶„ì„ê¸° ì—†ì´ ê³µë°± ê¸°ì¤€)
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        
    Returns:
        List[str]: í† í° ë¦¬ìŠ¤íŠ¸
        
    Examples:
        >>> simple_korean_tokenize("ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°‘ìŠµë‹ˆë‹¤")
        ['ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°‘ìŠµë‹ˆë‹¤']
        
        >>> simple_korean_tokenize("")
        []
    """
    if pd.isna(text) or text == '':
        return []
    
    # ê³µë°± ê¸°ì¤€ ë¶„ë¦¬
    tokens = str(text).split()
    
    # ê¸¸ì´ 1 ì´ìƒì¸ í† í°ë§Œ ë³´ì¡´
    tokens = [token for token in tokens if len(token) >= 1]
    
    return tokens


def preprocess_text_data(df: pd.DataFrame, 
                        text_column: str = 'document',
                        verbose: bool = True) -> pd.DataFrame:
    """
    ë°ì´í„°í”„ë ˆì„ì˜ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    
    í…ìŠ¤íŠ¸ ì •ì œ, ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°, ê¸¸ì´ ê³„ì‚°ì„ ì¼ê´„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        text_column: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª… (ê¸°ë³¸ê°’: 'document')
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
    Returns:
        DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ (cleaned_text, text_length ì»¬ëŸ¼ ì¶”ê°€)
        
    Examples:
        >>> df = pd.DataFrame({'document': ['ì¢‹ì€ ì˜í™”!!', ''], 'label': [1, 0]})
        >>> result = preprocess_text_data(df)
        >>> result.columns.tolist()
        ['document', 'label', 'cleaned_text', 'text_length']
    """
    if verbose:
        print(f"ğŸ“ {len(df)}ê°œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # ë³µì‚¬ë³¸ ìƒì„±
    processed_df = df.copy()
    
    # 1. í…ìŠ¤íŠ¸ ì •ì œ
    if verbose:
        tqdm.pandas(desc="í…ìŠ¤íŠ¸ ì •ì œ")
        processed_df['cleaned_text'] = processed_df[text_column].progress_apply(clean_korean_text)
    else:
        processed_df['cleaned_text'] = processed_df[text_column].apply(clean_korean_text)
    
    # 2. ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°
    before_len = len(processed_df)
    processed_df = processed_df[processed_df['cleaned_text'].str.len() > 0]
    after_len = len(processed_df)
    
    if verbose:
        print(f"ğŸ“Š ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°: {before_len:,} â†’ {after_len:,} ({before_len-after_len}ê°œ ì œê±°)")
    
    # 3. í…ìŠ¤íŠ¸ ê¸¸ì´ ì¶”ê°€
    processed_df['text_length'] = processed_df['cleaned_text'].str.len()
    
    # 4. ê¸°ë³¸ í†µê³„
    if verbose:
        mean_length = processed_df['text_length'].mean()
        median_length = processed_df['text_length'].median()
        print(f"ğŸ“ í‰ê·  ê¸¸ì´: {mean_length:.1f}ì")
        print(f"ğŸ“ ì¤‘ì•™ê°’: {median_length:.1f}ì")
    
    # ì¸ë±ìŠ¤ ë¦¬ì…‹
    processed_df = processed_df.reset_index(drop=True)
    
    return processed_df


def get_text_statistics(df: pd.DataFrame, 
                       text_column: str = 'cleaned_text') -> dict:
    """
    í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ìƒì„¸ í†µê³„ ì •ë³´ ë°˜í™˜
    
    Args:
        df: ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„
        text_column: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
        
    Returns:
        dict: í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    text_lengths = df[text_column].str.len()
    
    stats = {
        'count': len(df),
        'mean_length': text_lengths.mean(),
        'median_length': text_lengths.median(),
        'std_length': text_lengths.std(),
        'min_length': text_lengths.min(),
        'max_length': text_lengths.max(),
        'percentile_25': text_lengths.quantile(0.25),
        'percentile_75': text_lengths.quantile(0.75),
        'empty_count': (text_lengths == 0).sum()
    }
    
    return stats


def show_preprocessing_examples(original_df: pd.DataFrame,
                              processed_df: pd.DataFrame,
                              n_examples: int = 5,
                              text_column: str = 'document') -> None:
    """
    ì „ì²˜ë¦¬ ì „í›„ ë¹„êµ ì˜ˆì‹œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        original_df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        processed_df: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        n_examples: ì¶œë ¥í•  ì˜ˆì‹œ ê°œìˆ˜
        text_column: ì›ë³¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
    """
    print("ğŸ“ ì „ì²˜ë¦¬ ì „í›„ ë¹„êµ:")
    print("=" * 60)
    
    for i in range(min(n_examples, len(processed_df))):
        original = original_df.iloc[i][text_column]
        cleaned = processed_df.iloc[i]['cleaned_text']
        
        print(f"\nì˜ˆì‹œ {i+1}:")
        print(f"ì›ë³¸: {original}")
        print(f"ì •ì œ: {cleaned}")
        
        if original != cleaned:
            print("ğŸ”„ ë³€ê²½ë¨")
        else:
            print("âœ… ë³€ê²½ì—†ìŒ")
    
    print("=" * 60)


# í¸ì˜ í•¨ìˆ˜ë“¤
def quick_preprocess(texts: List[str]) -> List[str]:
    """
    í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[str]: ì •ì œëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    return [clean_korean_text(text) for text in texts]


def validate_preprocessing_result(df: pd.DataFrame) -> bool:
    """
    ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        df: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        bool: ê²€ì¦ í†µê³¼ ì—¬ë¶€
    """
    required_columns = ['cleaned_text', 'text_length']
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    for col in required_columns:
        if col not in df.columns:
            logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {col}")
            return False
    
    # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
    empty_texts = (df['cleaned_text'].str.len() == 0).sum()
    if empty_texts > 0:
        logger.warning(f"ë¹ˆ í…ìŠ¤íŠ¸ {empty_texts}ê°œ ë°œê²¬")
    
    # ê¸¸ì´ ì¼ê´€ì„± í™•ì¸
    calculated_lengths = df['cleaned_text'].str.len()
    length_mismatch = (calculated_lengths != df['text_length']).sum()
    
    if length_mismatch > 0:
        logger.error(f"ê¸¸ì´ ë¶ˆì¼ì¹˜: {length_mismatch}ê°œ")
        return False
    
    logger.info("ì „ì²˜ë¦¬ ê²°ê³¼ ê²€ì¦ ì™„ë£Œ")
    return True


if __name__ == "__main__":
    # ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª text_preprocessor.py ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_texts = [
        "ã…‹ã…‹ã…‹ã…‹ ë„ˆë¬´ ì¬ë°Œì–´ìš”!!!!",
        "ì´ ì˜í™”...ì •ë§ ìµœê³ ì…ë‹ˆë‹¤",
        "",
        "ì•„ ì§„ì§œ ë³„ë¡œì˜€ìŒ ã… ã… ã… "
    ]
    
    print("\ní…ìŠ¤íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸:")
    for text in test_texts:
        cleaned = clean_korean_text(text)
        print(f"ì›ë³¸: '{text}' â†’ ì •ì œ: '{cleaned}'")
    
    # ë°ì´í„°í”„ë ˆì„ í…ŒìŠ¤íŠ¸
    test_df = pd.DataFrame({
        'document': test_texts,
        'label': [1, 1, 0, 0]
    })
    
    print(f"\në°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
    result_df = preprocess_text_data(test_df, verbose=False)
    print(f"ê²°ê³¼ shape: {result_df.shape}")
    print(f"ì»¬ëŸ¼: {result_df.columns.tolist()}")
    
    print("âœ… ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")